# DeepSeek RAG with Fine-Tuned Electrical STEM Model

This project fine-tunes the **DeepSeek 8B** model on **electrical STEM data**, incorporating **LoRA** and **QLoRA** for parameter-efficient fine-tuning. A **Retrieval-Augmented Generation (RAG)** system is built using **Ollama** and **Milvus** for efficient information retrieval and response generation.

## üöÄ Features
- **Fine-tuning:** Utilizes **Unsloth** for optimizing DeepSeek 8B training.
- **Quantization:** Implements **LoRA** and **QLoRA** for efficient model compression.
- **Retrieval-Augmented Generation (RAG):** Leverages **Milvus** for vector storage and **Ollama** for model deployment.
- **Domain-Specific Training:** Focuses on **electrical STEM** datasets for accurate, field-specific responses.

## üõ†Ô∏è Tech Stack
- **DeepSeek 8B** ‚Äì Base LLM for fine-tuning
- **Unsloth** ‚Äì Optimized fine-tuning framework
- **LoRA / QLoRA** ‚Äì Parameter-efficient quantization
- **Ollama** ‚Äì Lightweight LLM inference
- **Milvus** ‚Äì High-performance vector database



